{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45980d4d-afef-4246-ba97-ecc184520b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 12:00:47.152319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-15 12:00:47.164032: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-15 12:00:47.167482: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-15 12:00:47.176732: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-15 12:00:48.112434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VITIS'] + '/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88955178-1536-4d75-808e-e2815435b981",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b31882f-f1a6-4244-9be4-51cc5fad1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "W_data = ak.from_parquet(\"W_data.parquet\")\n",
    "Z_data = ak.from_parquet(\"Z_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2aae0f9-7ef9-4eb3-b938-e9de7fa93922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels\n",
    "W_data[\"MET\"] = len(W_data)*[1]\n",
    "Z_data[\"MET\"] = len(Z_data)*[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c9d0cb-c52a-49f8-be79-1ac1c355bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and shuffle\n",
    "combined = ak.concatenate([W_data, Z_data])\n",
    "combined = combined[ak.argsort(np.random.rand(len(combined)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c932183-02b3-4501-a4fb-96d4cd386684",
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in [\"jet_pt\", \"jet_eta\", \"jet_phi\"]:\n",
    "    combined = ak.with_field(combined, combined[field][:, :3], field)\n",
    "    combined[field] = ak.fill_none(ak.pad_none(combined[field],3, axis = 1),0)\n",
    "\n",
    "for field in [\"lep_pt\", \"lep_eta\", \"lep_phi\"]:\n",
    "    combined = ak.with_field(combined, combined[field][:, :2], field)\n",
    "    combined[field] = ak.fill_none(ak.pad_none(combined[field],2, axis = 1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97da977a-77db-4dca-8390-9c95214eac9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [7.23e+04, 2.49e+04, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [2.46e+04, 0, 0],\n",
       " ...,\n",
       " [2.53e+04, 0, 0],\n",
       " [0, 0, 0],\n",
       " [3.47e+04, 2.05e+04, 2.03e+04],\n",
       " [2.38e+04, 0, 0],\n",
       " [2.76e+04, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0]]\n",
       "--------------------------------\n",
       "backend: cpu\n",
       "nbytes: 3.2 GB\n",
       "type: 101060956 * var * float64</pre>"
      ],
      "text/plain": [
       "<Array [[0, 0, 0], [0, ..., 0], ..., [0, 0, 0]] type='101060956 * var * flo...'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"jet_pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef414cf-5b94-446e-9038-db205765e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(combined))\n",
    "train_idx, test_idx = train_test_split(indices, stratify=combined[\"MET\"], test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c6f22b-4741-4722-824c-4df8c0b9e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined[train_idx]\n",
    "test = combined[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47bb5817-0bac-4a48-84f7-4b51dfbd04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = ak.to_numpy(train[\"MET\"])\n",
    "y_test = ak.to_numpy(test[\"MET\"])\n",
    "\n",
    "x_train = np.stack([\n",
    "    ak.to_numpy(train[\"jet_pt\"][:, 0]),\n",
    "    ak.to_numpy(train[\"jet_eta\"][:, 0]),\n",
    "    ak.to_numpy(train[\"jet_phi\"][:, 0]),\n",
    "    ak.to_numpy(train[\"jet_pt\"][:, 1]),\n",
    "    ak.to_numpy(train[\"jet_eta\"][:, 1]),\n",
    "    ak.to_numpy(train[\"jet_phi\"][:, 1]),\n",
    "    ak.to_numpy(train[\"jet_pt\"][:, 2]),\n",
    "    ak.to_numpy(train[\"jet_eta\"][:, 2]),\n",
    "    ak.to_numpy(train[\"jet_phi\"][:, 2]),\n",
    "    ak.to_numpy(train[\"lep_pt\"][:, 0]),\n",
    "    ak.to_numpy(train[\"lep_eta\"][:, 0]),\n",
    "    ak.to_numpy(train[\"lep_phi\"][:, 0]),\n",
    "    ak.to_numpy(train[\"lep_pt\"][:, 1]),\n",
    "    ak.to_numpy(train[\"lep_eta\"][:, 1]),\n",
    "    ak.to_numpy(train[\"lep_phi\"][:, 1]),\n",
    "    ak.to_numpy(train[\"met_et\"]),\n",
    "    ak.to_numpy(train[\"met_phi\"])\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac53de7-48ec-4bce-8547-7625b2bd7f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d50df88-e57c-4ea8-9481-a4fe9ce41674",
   "metadata": {},
   "source": [
    "# Constructing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3fa3e6-19fc-4b1b-9c1d-ba19b163cfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 12:04:15.608146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38148 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:27:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(17,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu1'))\n",
    "model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu2'))\n",
    "model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu3'))\n",
    "model.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cd1d82d-635b-4957-9696-fab3ef298a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in TF-Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1148, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1206, in compute_loss\n        return self.compiled_loss(\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m adam \u001b[38;5;241m=\u001b[39m Adam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39madam, loss\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m], metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file5rcxuba0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1148, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1206, in compute_loss\n        return self.compiled_loss(\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/frodriguez/.conda/envs/hls4ml-tutorial/lib/python3.12/site-packages/tf_keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size = 1024, epochs = 10, validation_split = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5700a3df-86c1-4a2e-8918-36994b4bb742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  4.57703281e+04, -2.31341910e+00, -7.48141587e-01,\n",
       "        4.22642891e+04, -1.75426650e+00,  1.85225403e+00,  2.20487051e+04,\n",
       "       -2.70963883e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae68c3-489c-4e7e-9384-4037bf06a219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
